{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3v_1fbJrKKU-"
   },
   "source": [
    "# ITU YZV302(3)E Deep Learning Course Fall 2024\n",
    "\n",
    "# HW3\n",
    "\n",
    "# Q1: RNN and LSTM (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T05:35:34.787025Z",
     "start_time": "2023-12-14T05:35:34.780623Z"
    },
    "id": "X8oJez8WKKVA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from DL.layer.recurrent_layers import RNNLayer, LSTMLayer\n",
    "from DL.checks import rel_error, grad_check\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCU9ECwwKKVA"
   },
   "source": [
    "## RNN [5 pts]\n",
    "\n",
    "Implement a simple RNNLayer in \"DL/layer/recurrent_layers.py\" . Learnable parameters are $W_x, W_h$ and $b$ which are set during initialization. Dimensions of parameters are given in comments.\n",
    "RNN layer should compute:\n",
    "\n",
    "$h^{(t)} = tanh(b + W_hh^{t-1} + W_xx^{t})$\n",
    "\n",
    "After your implementation, you can test your code for each method by using the tester functions below. Each function should return True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMa_UiN2KKVB"
   },
   "source": [
    "### Forward Step [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "id": "eBhanvWWKKVB",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def rnn_test_forward_step():\n",
    "    N, D, H = 3, 10, 4\n",
    "    rnn = RNNLayer(10, 4)\n",
    "    x = np.linspace(-0.4, 0.7, num=N*D).reshape(N, D)\n",
    "    prev_h = np.linspace(-0.2, 0.5, num=N*H).reshape(N, H)\n",
    "    rnn.Wx = np.linspace(-0.1, 0.9, num=D*H).reshape(D, H)\n",
    "    rnn.Wh = np.linspace(-0.3, 0.7, num=H*H).reshape(H, H)\n",
    "    rnn.b = np.linspace(-0.2, 0.4, num=H)\n",
    "\n",
    "    next_h, _ = rnn.forward_step(x, prev_h)\n",
    "    expected_next_h = np.array([\n",
    "      [-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "      [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],\n",
    "      [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])\n",
    "\n",
    "    print(rel_error(expected_next_h, next_h) < 1e-6)\n",
    "\n",
    "rnn_test_forward_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNKDEf_jKKVB"
   },
   "source": [
    "### Forward [1.5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "id": "Tx5pl12UKKVB",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def rnn_test_forward():\n",
    "    N, T, D, H = 2, 3, 4, 5\n",
    "    rnn = RNNLayer(4,5)\n",
    "    x = np.linspace(-0.1, 0.3, num=N*T*D).reshape(N, T, D)\n",
    "    prev_h = np.linspace(-0.3, 0.1, num=N*H).reshape(N, H)\n",
    "    rnn.Wx = np.linspace(-0.2, 0.4, num=D*H).reshape(D, H)\n",
    "    rnn.Wh = np.linspace(-0.4, 0.1, num=H*H).reshape(H, H)\n",
    "    rnn.b = np.linspace(-0.7, 0.1, num=H)\n",
    "\n",
    "    h = rnn.forward(x, prev_h)\n",
    "    expected_h = np.array([\n",
    "      [\n",
    "        [-0.42070749, -0.27279261, -0.11074945,  0.05740409,  0.22236251],\n",
    "        [-0.39525808, -0.22554661, -0.0409454,   0.14649412,  0.32397316],\n",
    "        [-0.42305111, -0.24223728, -0.04287027,  0.15997045,  0.35014525],\n",
    "      ],\n",
    "      [\n",
    "        [-0.55857474, -0.39065825, -0.19198182,  0.02378408,  0.23735671],\n",
    "        [-0.27150199, -0.07088804,  0.13562939,  0.33099728,  0.50158768],\n",
    "        [-0.51014825, -0.30524429, -0.06755202,  0.17806392,  0.40333043]]])\n",
    "\n",
    "    print(rel_error(expected_h[0], h[0]) < 1e-6)\n",
    "\n",
    "rnn_test_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzhD-Wo4KKVB"
   },
   "source": [
    "### Backward Step [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "id": "F5PAQEqEKKVB",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def rnn_test_backward_step():\n",
    "    np.random.seed(145)\n",
    "    N, D, H = 3, 10, 5\n",
    "    rnn = RNNLayer(D, H)\n",
    "\n",
    "    x = np.random.randn(N, D)\n",
    "    prev_h = np.random.randn(N, H)\n",
    "    rnn.Wx = np.random.randn(D, H)\n",
    "    rnn.Wh = np.random.randn(H, H)\n",
    "    rnn.b = np.random.randn(H)\n",
    "\n",
    "    out, cache = rnn.forward_step(x, prev_h)\n",
    "\n",
    "    dnext_h = np.linspace(-0.2, 0.4, num=N*H).reshape(N, H)\n",
    "\n",
    "    dx, dprev_h, dWx, dWh, db = rnn.backward_step(dnext_h, cache)\n",
    "    f = lambda _: rnn.forward_step(x, prev_h)[0]\n",
    "\n",
    "\n",
    "    dx_num = grad_check(f, x, dnext_h)\n",
    "    dprev_h_num = grad_check(f, prev_h, dnext_h)\n",
    "    dWx_num = grad_check(f, rnn.Wx, dnext_h)\n",
    "    dWh_num = grad_check(f, rnn.Wh, dnext_h)\n",
    "    db_num = grad_check(f, rnn.b, dnext_h)\n",
    "\n",
    "    print(rel_error(dx_num, dx) < 1e-6)\n",
    "    print(rel_error(dprev_h_num, dprev_h) < 1e-6)\n",
    "    print(rel_error(dWx_num, dWx) < 1e-6)\n",
    "    print(rel_error(dWh_num, dWh) < 1e-6)\n",
    "    print(rel_error(db_num, db) < 1e-6)\n",
    "\n",
    "rnn_test_backward_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yP0p79urKKVB"
   },
   "source": [
    "### Backward [1.5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "id": "rF_dzY9HKKVC",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def rnn_test_backward():\n",
    "    np.random.seed(145)\n",
    "\n",
    "    N, D, T, H = 3, 10, 7, 5\n",
    "    rnn = RNNLayer(D, H)\n",
    "\n",
    "    x = np.random.randn(N, T, D)\n",
    "    h0 = np.random.randn(N, H)\n",
    "    rnn.Wx = np.random.randn(D, H)\n",
    "    rnn.Wh = np.random.randn(H, H)\n",
    "    rnn.b = np.random.randn(H)\n",
    "\n",
    "    out = rnn.forward(x, h0)\n",
    "\n",
    "    dnext_h = np.random.randn(*out.shape)\n",
    "\n",
    "    rnn.backward(dnext_h)\n",
    "\n",
    "    dx, dh0, dWx, dWh, db = rnn.grad['dx'], rnn.grad['dh0'], rnn.grad['dWx'], rnn.grad['dWh'], rnn.grad['db']\n",
    "\n",
    "    f = lambda _: rnn.forward(x, h0)\n",
    "\n",
    "    dx_num = grad_check(f, x, dnext_h)\n",
    "    dh0_num = grad_check(f, h0, dnext_h)\n",
    "    dWx_num = grad_check(f, rnn.Wx, dnext_h)\n",
    "    dWh_num = grad_check(f, rnn.Wh, dnext_h)\n",
    "    db_num = grad_check(f, rnn.b, dnext_h)\n",
    "\n",
    "    print(rel_error(dx_num, dx) < 1e-6)\n",
    "    print(rel_error(dh0_num, dh0) < 1e-6)\n",
    "    print(rel_error(dWx_num, dWx) < 1e-6)\n",
    "    print(rel_error(dWh_num, dWh) < 1e-6)\n",
    "    print(rel_error(db_num, db) < 1e-6)\n",
    "\n",
    "rnn_test_backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8caRTKIKKVC"
   },
   "source": [
    "## LSTM [5 pts]\n",
    "\n",
    "Implement a simple LSTMLayer in \"DL/layer/recurrent\\_layers.py\" . Learnable parameters are $W_x, W_h$ and $b$ which are set during initialization. Dimensions of parameters are given in comments.\n",
    "LSTM layer should compute:\n",
    "\n",
    "$a = b + W_hh^{t-1} + W_xx^{t}$\n",
    "\n",
    "$a = [a_i, a_f, a_o, a_g]$\n",
    "\n",
    "$input = \\sigma(a_i)$ , $forget = \\sigma(a_f)$ , $output = \\sigma(a_o)$ , $input\\_gate = tanh(a_g)$\n",
    "\n",
    "$c^{(t)} = forget \\odot  c^{(t-1)} + input \\odot input\\_gate$\n",
    "\n",
    "$h^{(t)} = output \\odot  tanh(c^{(t)})$\n",
    "\n",
    "Note: forward function is used in order to obtain only hidden states for the input batch and it is assumed input batch is from the start of the sequence; therefore, cell state should be initialized to 0 and it is not necessary to return the resulting cell states.\n",
    "\n",
    "After your implementation, you can test your code for each method by using the tester functions below. Each function should return True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rt0ocO_IKKVC"
   },
   "source": [
    "### Forward Step [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "P25TA8hZKKVC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def lstm_test_forward_step():\n",
    "    N, D, H = 3, 4, 5\n",
    "    lstm = LSTMLayer(4, 5)\n",
    "    x = np.linspace(-0.4, 1.2, num=N*D).reshape(N, D)\n",
    "    prev_h = np.linspace(-0.3, 0.7, num=N*H).reshape(N, H)\n",
    "    prev_c = np.linspace(-0.4, 0.9, num=N*H).reshape(N, H)\n",
    "    lstm.Wx = np.linspace(-2.1, 1.3, num=4*D*H).reshape(D, 4 * H)\n",
    "    lstm.Wh = np.linspace(-0.7, 2.2, num=4*H*H).reshape(H, 4 * H)\n",
    "    lstm.b = np.linspace(0.3, 0.7, num=4*H)\n",
    "\n",
    "    next_h, next_c, _ = lstm.forward_step(x, prev_h, prev_c)\n",
    "\n",
    "    expected_next_h = np.asarray([\n",
    "        [ 0.24635157,  0.28610883,  0.32240467,  0.35525807,  0.38474904],\n",
    "        [ 0.49223563,  0.55611431,  0.61507696,  0.66844003,  0.7159181 ],\n",
    "        [ 0.56735664,  0.66310127,  0.74419266,  0.80889665,  0.858299  ]])\n",
    "    expected_next_c = np.asarray([\n",
    "        [ 0.32986176,  0.39145139,  0.451556,    0.51014116,  0.56717407],\n",
    "        [ 0.66382255,  0.76674007,  0.87195994,  0.97902709,  1.08751345],\n",
    "        [ 0.74192008,  0.90592151,  1.07717006,  1.25120233,  1.42395676]])\n",
    "\n",
    "    print(rel_error(expected_next_h, next_h) < 1e-6)\n",
    "    print(rel_error(expected_next_c, next_c) < 1e-6)\n",
    "\n",
    "lstm_test_forward_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M95Rv38wKKVC"
   },
   "source": [
    "### Forward [1.5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AMQ-2MS1KKVC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def lstm_test_forward():\n",
    "    N, D, H, T = 2, 5, 4, 3\n",
    "    lstm = LSTMLayer(5, 4)\n",
    "    x = np.linspace(-0.4, 0.6, num=N*T*D).reshape(N, T, D)\n",
    "    h0 = np.linspace(-0.4, 0.8, num=N*H).reshape(N, H)\n",
    "    lstm.Wx = np.linspace(-0.2, 0.9, num=4*D*H).reshape(D, 4 * H)\n",
    "    lstm.Wh = np.linspace(-0.3, 0.6, num=4*H*H).reshape(H, 4 * H)\n",
    "    lstm.b = np.linspace(0.2, 0.7, num=4*H)\n",
    "\n",
    "    h = lstm.forward(x, h0)\n",
    "\n",
    "    expected_h = np.asarray([\n",
    "     [[ 0.01764008,  0.01823233,  0.01882671,  0.0194232 ],\n",
    "      [ 0.11287491,  0.12146228,  0.13018446,  0.13902939],\n",
    "      [ 0.31358768,  0.33338627,  0.35304453,  0.37250975]],\n",
    "     [[ 0.45767879,  0.4761092,   0.4936887,   0.51041945],\n",
    "      [ 0.6704845,   0.69350089,  0.71486014,  0.7346449 ],\n",
    "      [ 0.81733511,  0.83677871,  0.85403753,  0.86935314]]])\n",
    "\n",
    "    print(rel_error(expected_h[0], h[0]) < 1e-6)\n",
    "\n",
    "lstm_test_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTtw5CZyKKVC"
   },
   "source": [
    "### Backward Step [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aKNiCeLVKKVC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def lstm_test_backward_step():\n",
    "    np.random.seed(132)\n",
    "\n",
    "    N, D, H = 4, 5, 6\n",
    "    lstm = LSTMLayer(5, 6)\n",
    "    x = np.random.randn(N, D)\n",
    "    prev_h = np.random.randn(N, H)\n",
    "    prev_c = np.random.randn(N, H)\n",
    "    lstm.Wx = np.random.randn(D, 4 * H)\n",
    "    lstm.Wh = np.random.randn(H, 4 * H)\n",
    "    lstm.b = np.random.randn(4 * H)\n",
    "\n",
    "    next_h, next_c, cache = lstm.forward_step(x, prev_h, prev_c)\n",
    "\n",
    "    dnext_h = np.random.randn(*next_h.shape)\n",
    "    dnext_c = np.random.randn(*next_c.shape)\n",
    "\n",
    "    f_h = lambda _: lstm.forward_step(x, prev_h, prev_c)[0]\n",
    "    f_c = lambda _: lstm.forward_step(x, prev_h, prev_c)[1]\n",
    "\n",
    "    dx_num = grad_check(f_h, x, dnext_h) + grad_check(f_c, x, dnext_c)\n",
    "    dprev_h_num = grad_check(f_h, prev_h, dnext_h) + grad_check(f_c, prev_h, dnext_c)\n",
    "    dprev_c_num = grad_check(f_h, prev_c, dnext_h) + grad_check(f_c, prev_c, dnext_c)\n",
    "    dWx_num = grad_check(f_h, lstm.Wx, dnext_h) + grad_check(f_c, lstm.Wx, dnext_c)\n",
    "    dWh_num = grad_check(f_h, lstm.Wh, dnext_h) + grad_check(f_c, lstm.Wh, dnext_c)\n",
    "    db_num = grad_check(f_h, lstm.b, dnext_h) + grad_check(f_c, lstm.b, dnext_c)\n",
    "\n",
    "    dx, dh, dc, dWx, dWh, db = lstm.backward_step(dnext_h, dnext_c, cache)\n",
    "\n",
    "    print(rel_error(dx_num, dx) < 1e-6)\n",
    "    print(rel_error(dprev_h_num, dh) < 1e-6)\n",
    "    print(rel_error(dprev_c_num, dc) < 1e-6)\n",
    "    print(rel_error(dWx_num, dWx) < 1e-6)\n",
    "    print(rel_error(dWh_num, dWh) < 1e-6)\n",
    "    print(rel_error(db_num, db) < 1e-6)\n",
    "\n",
    "lstm_test_backward_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Muamd4nHKKVC"
   },
   "source": [
    "### Backward [1.5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YS4QoBwxKKVC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def lstm_test_backward():\n",
    "    np.random.seed(231)\n",
    "\n",
    "    N, D, T, H = 2, 3, 10, 6\n",
    "\n",
    "    lstm = LSTMLayer(3, 6)\n",
    "\n",
    "    x = np.random.randn(N, T, D)\n",
    "    h0 = np.random.randn(N, H)\n",
    "    lstm.Wx = np.random.randn(D, 4 * H)\n",
    "    lstm.Wh = np.random.randn(H, 4 * H)\n",
    "    lstm.b = np.random.randn(4 * H)\n",
    "\n",
    "    out = lstm.forward(x, h0)\n",
    "\n",
    "    dnext_h = np.random.randn(*out.shape)\n",
    "\n",
    "    lstm.backward(dnext_h)\n",
    "    dx, dh0, dWx, dWh, db = lstm.grad['dx'], lstm.grad['dh0'], lstm.grad['dWx'], lstm.grad['dWh'], lstm.grad['db']\n",
    "\n",
    "    f = lambda _: lstm.forward(x, h0)\n",
    "\n",
    "    dx_num = grad_check(f, x, dnext_h)\n",
    "    dh0_num = grad_check(f, h0, dnext_h)\n",
    "    dWx_num = grad_check(f, lstm.Wx, dnext_h)\n",
    "    dWh_num = grad_check(f, lstm.Wh, dnext_h)\n",
    "    db_num = grad_check(f, lstm.b, dnext_h)\n",
    "\n",
    "    print(rel_error(dx_num, dx) < 1e-6)\n",
    "    print(rel_error(dh0_num, dh0) < 1e-6)\n",
    "    print(rel_error(dWx_num, dWx) < 1e-6)\n",
    "    print(rel_error(dWh_num, dWh) < 1e-6)\n",
    "    print(rel_error(db_num, db) < 1e-6)\n",
    "\n",
    "lstm_test_backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
